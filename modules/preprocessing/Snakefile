""" 
    This snakemake file includes preprocessing workflows
"""

import os 
from snakemake.utils import makedirs 

## Path to config file
# configfile: "../../config/config.yaml"
# configfile: "/stanley/WangLab/jiahao/Github/starfinder/test/wendy_test.yaml"
configfile: "/home/unix/jiahao/wanglab/jiahao/Github/starfinder/test/wendy_test.yaml"

## Define specific list of positions to run the pipeline for testing/re-runs
if config['mode'] == "seq":
    # for all tiles: 
    FOVS = [config['fov_naming_pattern'].format(i=j) for j in range(1, config['n_fovs']+1)] 
elif config['mode'] == "subset":
    # for subset of tiles:
    FOVS = [config['fov_naming_pattern'].format(i=j) for j in config['subset_list']] 
else:
    print("Please provide a valid running mode!")

## TO-DO: once debugged, implement this fn to scale up resources in resubmissions of failed attempts
# def getMemoryMbs(rule, wildcards, attempt):

### ==================== [ Helper functions ] =========================

# helper function to output filepath string to registration outputs
def get_output_path(subdir, sub_sample_index=0):
    path = os.path.join(config['output_dir'], config['sample'], config['sub_sample'][0], config['subdirs'][subdir])
    return path


### ==================== [ Rules ] =========================

# rule pp: # rule "all" requires final output as input and therefore runs every rule
#     input: 
#         # input for "all" is the desired end output of all rules
#         expand("{outpath}/{tile}/goodPoints_dapi.tif", 
#             outpath=getOutpath('registration'), 
#             tile=TILES
#         ),
#         expand("{outpath}/{protein_round}/{protein_stain}/{tile}.tif", 
#             outpath=getOutpath('registration'),
#             protein_round=config['protein_round'],
#             protein_stain=config['protein_stains'],
#             tile = TILES
#         )

# rule setup:
#     input: 
#         tile_dir=f"/stanley/WangLab/Data/Processed/{config['sample']}/{config['sub_sample'][0]}" # data files in Data/Processed
#     output: 
#         symlink=directory(get_output_path('source_data')) # symlinks in projdir/01.data
#     shell: 
#         "ln -sf {input.tile_dir} {output.symlink}"

# rule min_max_normalization: 
#     """
#     Perform intensity scaling
#     """
#     input: 
#         # position directory in 01_data
#         f"{get_output_path('source_data')}/round1/{{fov}}"
#     output: 
#         # pped images 
#         expand("{current_outpath}/{{fov}}/interm/ppedImages_{ch}.tif",
#             current_outpath=get_output_path('registration'),
#             ch=range(1,config['n_chs']+1),
#         ),
#     resources: 
#         mem_mb=config['resources']['preprocessing']
#     params: 
#         mode="global_registration"
#     script: 
#         "scripts/pp.py"

rule all:
    input:
        expand("{output_dir}/{sample}/images/DAPI/{fov}.tif",
                output_dir=config['output_dir'],
                sample=config['sample'],
                fov=FOVS),
        expand("{output_dir}/{sample}/images/ref_merged/{fov}.tif",
                output_dir=config['output_dir'],
                sample=config['sample'],
                fov=FOVS)

rule registration_test:
    input:
        input_folder=f"{config['input_dir']}/{config['sample']}/round1/{{fovID}}"
    output:
        expand("{output_dir}/{sample}/images/DAPI/{{fovID}}.tif",
                output_dir=config['output_dir'],
                sample=config['sample']),
        expand("{output_dir}/{sample}/images/ref_merged/{{fovID}}.tif",
                output_dir=config['output_dir'],
                sample=config['sample'])
    resources:
        mem_mb=config['resources']['preprocessing']
    wildcard_constraints:
        fovID = '\w+'
    script:
        "scripts/registration_test.py"



# rule pp:
#     input:
#         step_out=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig_end.txt"


# rule step_1:
#     input:
#         tile_dir=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}"
#     output:
#         step_1_out=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig.txt"
#     shell:
#         "echo step1 > {output.step_1_out}"

# rule step_2:
#     input:
#         tile_dir=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig.txt"
#     output:
#         step_2_out=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig_2.txt"
#     shell:
#         # "cat {input.tile_dir} | echo step2 is done > {output.step_2_out}"   
#         "echo step2 is done >> {input.tile_dir} & echo step2 > {output.step_2_out}"

# rule step_3:
#     input:
#         tile_dir=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig_2.txt"
#     output:
#         step_3_out=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig_3.txt"
#     shell:
#         "cat {input.tile_dir} | echo step3 is done > {output.step_3_out}"   

# rule step_4:
#     input:
#         tile_dir=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig_2.txt",
#         orig_dir=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig.txt"
#     output:
#         step_4_out=f"/stanley/WangLab/Data/Analyzed/{config['sample']}/{config['sub_sample'][0]}/orig_end.txt"
#     shell:
#         "echo step3 is done >> {input.orig_dir} & echo step_3 > {output.step_4_out}"



# rule local_registration:
#     """
#     """
#     input:
#         # coords_mat subtile configuration
#         f"{getOutpath('registration')}/{{pos}}/interm/coords_mat_{config['sqrt_pieces']**2}.csv",
#         # registered images subtile
#         f"{getOutpath('registration')}/{{pos}}/interm/registeredImages_t{{subtile,\d+}}_{config['sqrt_pieces']**2}.mat",
#         # genes.csv file 
#         f"{getOutpath('source_data')}/genes.csv"
#     output:
#         # goodPoints_{spotfinding_method}_t{subtile}.csv (spot-finding results for each subtile)
#         f"{getOutpath('registration')}/{{pos}}/interm/goodPoints_{config['spotfinding_method']}_t{{subtile,\d+}}_{config['sqrt_pieces']**2}.csv"
#     resources:
#         mem_mb=config['resources']['local_registration']
#     params: 
#         mode="local_registration"
#     script: 
#         "scripts/rsf.py"

# rule stitch:
#     """
#         Wildcard: pos = Position number
#     """
#     input:
#         # coords_mat subtile configuration
#         f"{getOutpath('registration')}/{{pos}}/interm/coords_mat_{config['sqrt_pieces']**2}.csv",
#         # goodPoints_{spotfinding_method}_t{subtile}.csv (spot-finding results for each subtile)
#         expand("{outpath}/{{pos}}/interm/goodPoints_{sf_method}_t{subtile}_{n_subtiles}.csv", 
#             outpath=getOutpath('registration'), 
#             sf_method=config['spotfinding_method'], 
#             subtile=range(1,config['sqrt_pieces']**2+1),
#             n_subtiles=config['sqrt_pieces']**2
#         )
#     output:
#         # final spot-finding results for each position
#         f"{getOutpath('registration')}/{{pos}}/goodPoints_{config['spotfinding_method']}.csv"
#     resources:
#         mem_mb=config['resources']['stitch']
#     params:
#         mode = "stitch"
#     script: "scripts/rsf.py" 

# rule plot_spot_finding:
#     """
#     """
#     input:
#         # DAPI image in reference round (round1)
#         dapi=f"{getOutpath('source_data')}/round1/{{pos}}",
#         # round1 merged tiff 
#         r1max=f"{getOutpath('registration')}/{{pos}}/interm/r1merged.tif",
#         # final spot-finding results for each position
#         goodReads=f"{getOutpath('registration')}/{{pos}}/goodPoints_{config['spotfinding_method']}.csv"
#     output:
#         # goodPoints on DAPI
#         goodPoints_dapi=f"{getOutpath('registration')}/{{pos}}/goodPoints_dapi.tif",
#         # goodPoints on r1max
#         goodPoints_r1max=f"{getOutpath('registration')}/{{pos}}/goodPoints_r1max.tif"
#     resources:
#         mem_mb=config['resources']['plot_spot_finding']
#     script: "scripts/plot_rsf.py"

# rule nuclei_protein_registration:
#     """
#     """
#     input:
#         # Protein round 
#         dapi=directory(f"{getOutpath('source_data')}/{config['protein_round']}/{{pos}}/")
#     output:
#         # Registered protein images 
#         expand("{outpath}/{protein_round}/{protein_stain}/{{pos}}.tif", 
#             outpath=getOutpath('registration'),
#             protein_round=config['protein_round'],
#             protein_stain=config['protein_stains']
#         )
#     wildcard_constraints:
#         pos = '\w+'
#     resources:
#         mem_mb=config['resources']['nuclei_protein_registration']
#     params:
#         mode = "nuclei_protein_registration"
#     script: "scripts/rsf.py"
