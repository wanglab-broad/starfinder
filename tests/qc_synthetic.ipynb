{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC: Synthetic Data Generator Validation\n",
    "\n",
    "This notebook validates the synthetic data generator (`starfinder.testdata`) by checking:\n",
    "1. Dataset structure and file existence\n",
    "2. Two-base encoding correctness\n",
    "3. Spot positions and visualization\n",
    "4. Channel assignments\n",
    "5. 3D visualization with napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup - imports\nimport sys\nsys.path.insert(0, \"../src/python\")\n\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nfrom starfinder.testdata import get_preset_config\nfrom starfinder.testdata.synthetic import (\n    encode_barcode_to_colors,\n    TEST_CODEBOOK,\n    COLOR_TO_CHANNEL,\n)\nfrom starfinder.io import load_multipage_tiff, load_image_stacks\n\n# Path to mini dataset\nMINI_DATASET_PATH = Path(\"fixtures/synthetic/mini\")\nprint(f\"Dataset path: {MINI_DATASET_PATH.absolute()}\")\nprint(f\"Dataset exists: {MINI_DATASET_PATH.exists()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify Dataset Structure\n",
    "\n",
    "Check that all expected files and directories exist in the mini dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all files/dirs exist\n",
    "def check_dataset_structure(dataset_path: Path):\n",
    "    \"\"\"Verify all expected files and directories exist.\"\"\"\n",
    "    checks = []\n",
    "    \n",
    "    # Top-level files\n",
    "    checks.append((\"codebook.csv\", (dataset_path / \"codebook.csv\").exists()))\n",
    "    checks.append((\"ground_truth.json\", (dataset_path / \"ground_truth.json\").exists()))\n",
    "    \n",
    "    # Load config to get expected structure\n",
    "    config = get_preset_config(\"mini\")\n",
    "    \n",
    "    # Check FOV directories\n",
    "    for fov_idx in range(config.n_fovs):\n",
    "        fov_id = f\"FOV_{fov_idx + 1:03d}\"\n",
    "        fov_dir = dataset_path / fov_id\n",
    "        checks.append((f\"{fov_id}/\", fov_dir.exists()))\n",
    "        \n",
    "        # Check round directories\n",
    "        for round_idx in range(1, config.n_rounds + 1):\n",
    "            round_dir = fov_dir / f\"round{round_idx}\"\n",
    "            checks.append((f\"{fov_id}/round{round_idx}/\", round_dir.exists()))\n",
    "            \n",
    "            # Check channel files\n",
    "            for ch in range(config.n_channels):\n",
    "                tiff_path = round_dir / f\"ch{ch:02d}.tif\"\n",
    "                checks.append((f\"{fov_id}/round{round_idx}/ch{ch:02d}.tif\", tiff_path.exists()))\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Dataset Structure Check:\")\n",
    "    print(\"=\" * 50)\n",
    "    all_passed = True\n",
    "    for name, exists in checks:\n",
    "        status = \"PASS\" if exists else \"FAIL\"\n",
    "        if not exists:\n",
    "            all_passed = False\n",
    "        print(f\"  [{status}] {name}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Overall: {'ALL CHECKS PASSED' if all_passed else 'SOME CHECKS FAILED'}\")\n",
    "    return all_passed\n",
    "\n",
    "check_dataset_structure(MINI_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validate Two-Base Encoding\n",
    "\n",
    "Verify that the two-base encoding works correctly for all genes in TEST_CODEBOOK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print encoding for all genes in TEST_CODEBOOK, verify CACGC -> 4422\n",
    "print(\"Two-Base Encoding Validation:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Gene':<10} {'Barcode':<10} {'Reversed':<10} {'Color Seq':<12} {'Expected'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Known expected encoding for CACGC\n",
    "# CACGC reversed = CGCAC\n",
    "# CG -> 4, GC -> 4, CA -> 2, AC -> 2 => \"4422\"\n",
    "expected_encodings = {\n",
    "    \"CACGC\": \"4422\",  # Explicitly stated in task\n",
    "}\n",
    "\n",
    "all_valid = True\n",
    "for gene, barcode in TEST_CODEBOOK:\n",
    "    color_seq = encode_barcode_to_colors(barcode)\n",
    "    reversed_barcode = barcode[::-1]\n",
    "    \n",
    "    # Check if we have an expected value\n",
    "    expected = expected_encodings.get(barcode, \"--\")\n",
    "    if expected != \"--\":\n",
    "        match = \"MATCH\" if color_seq == expected else \"MISMATCH\"\n",
    "        if color_seq != expected:\n",
    "            all_valid = False\n",
    "    else:\n",
    "        match = \"\"\n",
    "    \n",
    "    print(f\"{gene:<10} {barcode:<10} {reversed_barcode:<10} {color_seq:<12} {expected:<8} {match}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nVerification: CACGC -> {encode_barcode_to_colors('CACGC')} (expected: 4422)\")\n",
    "print(f\"Result: {'PASS' if encode_barcode_to_colors('CACGC') == '4422' else 'FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Spot Positions\n",
    "\n",
    "Load ground_truth.json and overlay spots on max projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground_truth.json, overlay spots on max projection using matplotlib\n",
    "\n",
    "# Load ground truth\n",
    "with open(MINI_DATASET_PATH / \"ground_truth.json\") as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "print(f\"Ground truth version: {ground_truth['version']}\")\n",
    "print(f\"Image shape (Z, Y, X): {ground_truth['image_shape']}\")\n",
    "print(f\"Number of rounds: {ground_truth['n_rounds']}\")\n",
    "print(f\"Number of channels: {ground_truth['n_channels']}\")\n",
    "print(f\"Number of FOVs: {len(ground_truth['fovs'])}\")\n",
    "\n",
    "# Get FOV_001 data\n",
    "fov_data = ground_truth[\"fovs\"][\"FOV_001\"]\n",
    "spots = fov_data[\"spots\"]\n",
    "print(f\"\\nNumber of spots in FOV_001: {len(spots)}\")\n",
    "\n",
    "# Load round1 images and create max projection\n",
    "round1_dir = MINI_DATASET_PATH / \"FOV_001\" / \"round1\"\n",
    "max_proj = None\n",
    "for ch in range(4):\n",
    "    img = load_multipage_tiff(round1_dir / f\"ch{ch:02d}.tif\", convert_uint8=False)\n",
    "    ch_max = img.max(axis=0)\n",
    "    if max_proj is None:\n",
    "        max_proj = ch_max.astype(np.float32)\n",
    "    else:\n",
    "        max_proj = np.maximum(max_proj, ch_max)\n",
    "\n",
    "# Plot with spot overlays\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(max_proj, cmap=\"gray\")\n",
    "ax.set_title(\"FOV_001 Round1 Max Projection with Ground Truth Spots\")\n",
    "\n",
    "# Overlay spots\n",
    "colors = plt.cm.tab10.colors\n",
    "gene_to_color = {gene: colors[i % len(colors)] for i, (gene, _) in enumerate(TEST_CODEBOOK)}\n",
    "\n",
    "for spot in spots:\n",
    "    z, y, x = spot[\"position\"]\n",
    "    gene = spot[\"gene\"]\n",
    "    ax.scatter(x, y, c=[gene_to_color[gene]], s=50, marker=\"o\", alpha=0.7, edgecolors=\"white\", linewidths=0.5)\n",
    "\n",
    "# Add legend\n",
    "for gene, color in gene_to_color.items():\n",
    "    ax.scatter([], [], c=[color], label=gene, s=50)\n",
    "ax.legend(loc=\"upper right\", title=\"Genes\")\n",
    "\n",
    "ax.set_xlabel(\"X (pixels)\")\n",
    "ax.set_ylabel(\"Y (pixels)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print first few spots\n",
    "print(\"\\nFirst 5 spots:\")\n",
    "for spot in spots[:5]:\n",
    "    print(f\"  {spot['gene']}: pos={spot['position']}, barcode={spot['barcode']}, color_seq={spot['color_seq']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Spots Appear in Correct Channels\n",
    "\n",
    "Check that each spot appears in the expected channel based on its color_seq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that spots appear in expected channels based on color_seq\n",
    "\n",
    "def verify_spot_in_channel(img_stack, z, y, x, expected_intensity_above_bg=50):\n",
    "    \"\"\"Check if a spot exists at the given location.\n",
    "    \n",
    "    Returns the intensity at the spot location and whether it's above background.\n",
    "    \"\"\"\n",
    "    # Get local region around spot\n",
    "    z_min, z_max = max(0, z-1), min(img_stack.shape[0], z+2)\n",
    "    y_min, y_max = max(0, y-2), min(img_stack.shape[1], y+3)\n",
    "    x_min, x_max = max(0, x-2), min(img_stack.shape[2], x+3)\n",
    "    \n",
    "    local_region = img_stack[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "    max_intensity = local_region.max()\n",
    "    \n",
    "    # Estimate background from image corners\n",
    "    bg_estimate = np.mean([\n",
    "        img_stack[:, :10, :10].mean(),\n",
    "        img_stack[:, :10, -10:].mean(),\n",
    "        img_stack[:, -10:, :10].mean(),\n",
    "        img_stack[:, -10:, -10:].mean(),\n",
    "    ])\n",
    "    \n",
    "    is_above_bg = max_intensity > (bg_estimate + expected_intensity_above_bg)\n",
    "    return max_intensity, is_above_bg, bg_estimate\n",
    "\n",
    "# Load all round1 channels\n",
    "round1_dir = MINI_DATASET_PATH / \"FOV_001\" / \"round1\"\n",
    "channel_stacks = []\n",
    "for ch in range(4):\n",
    "    img = load_multipage_tiff(round1_dir / f\"ch{ch:02d}.tif\", convert_uint8=False)\n",
    "    channel_stacks.append(img)\n",
    "\n",
    "print(\"Spot Channel Verification (Round 1):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Spot':<6} {'Gene':<8} {'Position':<15} {'Expected Ch':<12} {'Intensities (ch0-3)':<30} {'Pass'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "n_passed = 0\n",
    "n_total = len(spots)\n",
    "\n",
    "for i, spot in enumerate(spots):\n",
    "    z, y, x = spot[\"position\"]\n",
    "    gene = spot[\"gene\"]\n",
    "    color_seq = spot[\"color_seq\"]\n",
    "    \n",
    "    # Round 1 corresponds to first color in sequence (index 0)\n",
    "    expected_color = color_seq[0]\n",
    "    expected_channel = COLOR_TO_CHANNEL[expected_color]\n",
    "    \n",
    "    # Get intensities at spot location for all channels\n",
    "    intensities = []\n",
    "    for ch in range(4):\n",
    "        max_int, is_above, bg = verify_spot_in_channel(channel_stacks[ch], z, y, x)\n",
    "        intensities.append(max_int)\n",
    "    \n",
    "    # Check if expected channel has highest intensity\n",
    "    max_ch = np.argmax(intensities)\n",
    "    passed = max_ch == expected_channel\n",
    "    if passed:\n",
    "        n_passed += 1\n",
    "    \n",
    "    pos_str = f\"({z},{y},{x})\"\n",
    "    int_str = \", \".join([f\"{int(v):3d}\" for v in intensities])\n",
    "    status = \"PASS\" if passed else f\"FAIL (got ch{max_ch})\"\n",
    "    \n",
    "    print(f\"{i:<6} {gene:<8} {pos_str:<15} ch{expected_channel:<11} [{int_str}]  {status}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Summary: {n_passed}/{n_total} spots appear in correct channel ({100*n_passed/n_total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. napari 3D Visualization with Spots\n",
    "\n",
    "Visualize the volume in 3D with spot markers using napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# napari with viewer.add_points() for spots\n",
    "import napari\n",
    "\n",
    "# Load round1 as 4-channel stack (Z, Y, X, C)\n",
    "round1_dir = MINI_DATASET_PATH / \"FOV_001\" / \"round1\"\n",
    "channel_order = [f\"ch{i:02d}\" for i in range(4)]\n",
    "volume = load_image_stacks(round1_dir, channel_order=channel_order)\n",
    "print(f\"Loaded volume shape (Z, Y, X, C): {volume.shape}\")\n",
    "\n",
    "# Extract spot positions as (Z, Y, X) array\n",
    "spot_positions = np.array([spot[\"position\"] for spot in spots])\n",
    "spot_genes = [spot[\"gene\"] for spot in spots]\n",
    "\n",
    "# Create gene-to-color mapping for napari\n",
    "unique_genes = list(set(spot_genes))\n",
    "gene_colors = {\n",
    "    \"GeneA\": \"red\",\n",
    "    \"GeneB\": \"green\",\n",
    "    \"GeneC\": \"blue\",\n",
    "    \"GeneD\": \"yellow\",\n",
    "    \"GeneE\": \"magenta\",\n",
    "    \"GeneF\": \"cyan\",\n",
    "    \"GeneG\": \"orange\",\n",
    "    \"GeneH\": \"pink\",\n",
    "}\n",
    "spot_colors = [gene_colors.get(g, \"white\") for g in spot_genes]\n",
    "\n",
    "# Create napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add each channel as a separate image layer\n",
    "channel_names = [\"Ch0 (Color 1)\", \"Ch1 (Color 2)\", \"Ch2 (Color 3)\", \"Ch3 (Color 4)\"]\n",
    "channel_colormaps = [\"red\", \"green\", \"blue\", \"magenta\"]\n",
    "for ch in range(4):\n",
    "    viewer.add_image(\n",
    "        volume[:, :, :, ch],\n",
    "        name=channel_names[ch],\n",
    "        colormap=channel_colormaps[ch],\n",
    "        blending=\"additive\",\n",
    "        visible=True,\n",
    "    )\n",
    "\n",
    "# Add spot positions as points\n",
    "viewer.add_points(\n",
    "    spot_positions,\n",
    "    name=\"Ground Truth Spots\",\n",
    "    size=8,\n",
    "    face_color=spot_colors,\n",
    "    edge_color=\"white\",\n",
    "    edge_width=0.5,\n",
    "    symbol=\"disc\",\n",
    ")\n",
    "\n",
    "# Add text annotations for genes (optional, can be slow for many spots)\n",
    "viewer.add_points(\n",
    "    spot_positions,\n",
    "    name=\"Gene Labels\",\n",
    "    size=0,\n",
    "    text={\n",
    "        \"string\": spot_genes,\n",
    "        \"size\": 8,\n",
    "        \"color\": \"white\",\n",
    "        \"anchor\": \"upper_left\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nnapari viewer opened with:\")\n",
    "print(f\"  - 4 channel image layers\")\n",
    "print(f\"  - {len(spots)} ground truth spot markers\")\n",
    "print(\"\\nUse the layer controls to toggle visibility and adjust contrast.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "| Check | Description | Status |\n",
    "|-------|-------------|--------|\n",
    "| 1 | Dataset structure (all files/dirs exist) | Run cell 2 |\n",
    "| 2 | Two-base encoding (CACGC -> 4422) | Run cell 3 |\n",
    "| 3 | Spot positions overlay on max projection | Run cell 4 |\n",
    "| 4 | Spots appear in correct channels | Run cell 5 |\n",
    "| 5 | 3D visualization in napari | Run cell 6 |\n",
    "\n",
    "### Expected Results\n",
    "\n",
    "- **Structure**: All 16 TIFF files (4 rounds x 4 channels) should exist for FOV_001\n",
    "- **Encoding**: `CACGC` should encode to `4422` using the two-base color-space encoding\n",
    "- **Spots**: 20 spots should be visible in the max projection, colored by gene\n",
    "- **Channels**: Each spot should have highest intensity in the channel corresponding to its color_seq\n",
    "- **3D View**: napari should show all 4 channels with spot markers at correct Z positions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}