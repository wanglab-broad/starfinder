{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cd2c4a-420c-47ea-be60-5eaed366f3ae",
   "metadata": {},
   "source": [
    "# ClusterMap stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9282d5e-84ef-40d5-9460-6919be80ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tif\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import anndata as ad\n",
    "from starmap.sequencing import *\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "from skimage.filters import median, gaussian, threshold_otsu\n",
    "from skimage.morphology import disk, binary_dilation\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28987e61-73f9-41a9-b76f-e346cc707f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load genes.csv\n",
    "def load_genes(base_path):\n",
    "    genes2seqs = {}\n",
    "    seqs2genes = {}\n",
    "    with open(os.path.join(base_path, \"genes.csv\"), encoding='utf-8-sig') as f:\n",
    "        for l in f:\n",
    "            fields = l.rstrip().split(\",\")\n",
    "            curr_seg = \"\".join([str(s+1) for s in encode_SOLID(fields[1][::-1])])\n",
    "            curr_seg = curr_seg[5:] + curr_seg[:4]\n",
    "            # print(curr_seg)\n",
    "            genes2seqs[fields[0]] = curr_seg\n",
    "            seqs2genes[genes2seqs[fields[0]]] = fields[0]\n",
    "            \n",
    "    return genes2seqs, seqs2genes\n",
    "\n",
    "def closest_node(node, nodes):\n",
    "    closest_index = distance.cdist([node], nodes).argmin()\n",
    "    return nodes[closest_index], closest_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ac1de-48a4-4497-9941-202bb08efea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create blank tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bdf94-d1c8-473f-a8e3-123608eddb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tifffile import imwrite\n",
    "import os\n",
    "\n",
    "x, y, z = [2048, 2048, 35]\n",
    "output_dir = 'Z:/jiahao/Github/RIBOmap/segmentation-stitching/'\n",
    "\n",
    "# Create blank tile\n",
    "blank_3d = np.zeros((z, x, y), dtype=np.uint8)\n",
    "blank_2d = np.zeros((x, y), dtype=np.uint8)\n",
    "\n",
    "# Save blank tile to output directory\n",
    "imwrite(os.path.join(output_dir, 'blank.tif'), blank_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b908052-0345-4ad3-853f-8b3b1aa3abc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create round1 merged rotated max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903d49e-c54f-4db6-8bef-aa831f228c9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RIBOmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d42297-af8e-445d-ad29-b3f7df220456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "data_dir = 'Z:/Data/Processed/2021-11-23-Hu-MouseBrainRIBOmap/'\n",
    "tiles = sorted([d for d in os.listdir(os.path.join(data_dir, 'round1')) if \"Position\" in d])\n",
    "# tiles = tiles[3:4]\n",
    "\n",
    "round1_merged_rotated_max_path = os.path.join(data_dir, 'output/max_cluster/round1_merged_rotated_max')\n",
    "if not os.path.exists(round1_merged_rotated_max_path):\n",
    "    os.mkdir(round1_merged_rotated_max_path)\n",
    "    \n",
    "dapi_rotated_max_path = os.path.join(data_dir, 'output/max_cluster/dapi_rotated_max')\n",
    "if not os.path.exists(dapi_rotated_max_path):\n",
    "    os.mkdir(dapi_rotated_max_path)\n",
    "    \n",
    "# load the images \n",
    "for t in tqdm(tiles):\n",
    "    \n",
    "    # round1 merged\n",
    "    round1_merged_path = os.path.join(data_dir, 'output/max_cluster/round1_merged', f'{t}.tif')\n",
    "    round1_merged = imread(round1_merged_path)\n",
    "    round1_merged_rotated_max = rotate(round1_merged.max(axis=0), -90)\n",
    "    round1_merged_rotated_max = img_as_ubyte(round1_merged_rotated_max)\n",
    "    imwrite(os.path.join(round1_merged_rotated_max_path, f'{t}.tif'), round1_merged_rotated_max)\n",
    "    \n",
    "    # dapi \n",
    "    dapi_path = os.path.join(data_dir, 'round1', t, '*_ch04.tif')\n",
    "    dapi = imread(dapi_path)\n",
    "    dapi_max = rotate(dapi.max(axis=0), -90)\n",
    "    dapi_max = img_as_ubyte(dapi_max)\n",
    "    imwrite(os.path.join(dapi_rotated_max_path, f'{t}.tif'), dapi_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec2e2c-2a1e-4b8a-9373-b71ee1eb8361",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RIBOmap - split channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683ddd4-fb5f-46ca-927d-c63ab9df3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "data_dir = 'Z:/Data/Processed/2021-11-23-Hu-MouseBrainRIBOmap/'\n",
    "\n",
    "coords_df4 = pd.read_csv('Z:/jiahao/Github/RIBOmap/segmentation-stitching/RIBOmap/results/tuned_coords.csv', index_col=0)\n",
    "coords_df4 = coords_df4.loc[coords_df4['tile'] != 0, :]\n",
    "\n",
    "col_min = 20000\n",
    "row_min = 45000\n",
    "col_max = 45000\n",
    "row_max = 69000\n",
    "\n",
    "corrds_logical = (coords_df4['column'].isin(range(col_min, col_max))) & (coords_df4['row'].isin(range(row_min, row_max)))\n",
    "scoords_df = coords_df4.loc[corrds_logical, :]\n",
    "\n",
    "tiles = sorted([f\"Position{d}\" for d in scoords_df['tile']])\n",
    "# tiles = tiles[3:4]\n",
    "\n",
    "# load the images \n",
    "for i in range(5): \n",
    "    # print(i)\n",
    "    if i < 4:\n",
    "        current_output_path = os.path.join(data_dir, f'output/max_cluster/round1_ch0{i}_rotated_max')\n",
    "        if not os.path.exists(current_output_path):\n",
    "            os.mkdir(current_output_path)\n",
    "\n",
    "        for j, t in enumerate(tqdm(tiles)):\n",
    "\n",
    "            # round1\n",
    "            current_input_path = os.path.join(data_dir, 'round1', t)\n",
    "            current_img_file = [f for f in os.listdir(current_input_path) if f'ch0{i}' in f][0]\n",
    "            current_img = imread(os.path.join(current_input_path, current_img_file))\n",
    "            current_img_rotated_max = rotate(current_img.max(axis=0), -90)\n",
    "            current_img_rotated_max = img_as_ubyte(current_img_rotated_max)\n",
    "            imwrite(os.path.join(current_output_path, f'tile_{j}.tif'), current_img_rotated_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1af070-a845-44b2-a53e-ebd72ef28a61",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STARmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bf835-cd90-4e5b-833f-ecf6f2cb30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "data_dir = 'Z:/Data/Processed/2021-11-23-Hu-MouseBrainSTARmap/'\n",
    "tiles = sorted([d for d in os.listdir(os.path.join(data_dir, 'round1')) if \"Position\" in d])\n",
    "# tiles = tiles[3:4]\n",
    "\n",
    "round1_merged_rotated_max_path = os.path.join(data_dir, 'output/max_cluster/round1_merged_rotated_max')\n",
    "if not os.path.exists(round1_merged_rotated_max_path):\n",
    "    os.mkdir(round1_merged_rotated_max_path)\n",
    "    \n",
    "dapi_rotated_max_path = os.path.join(data_dir, 'output/max_cluster/dapi_rotated_max')\n",
    "if not os.path.exists(dapi_rotated_max_path):\n",
    "    os.mkdir(dapi_rotated_max_path)\n",
    "    \n",
    "# load the images \n",
    "for t in tqdm(tiles):\n",
    "    \n",
    "    # round1 merged\n",
    "    round1_merged_path = os.path.join(data_dir, 'output/max_cluster/round1_merged', f'{t}.tif')\n",
    "    round1_merged = imread(round1_merged_path)\n",
    "    round1_merged_rotated_max = rotate(round1_merged.max(axis=0), -90)\n",
    "    round1_merged_rotated_max = img_as_ubyte(round1_merged_rotated_max)\n",
    "    imwrite(os.path.join(round1_merged_rotated_max_path, f'{t}.tif'), round1_merged_rotated_max)\n",
    "    \n",
    "    # dapi \n",
    "    dapi_path = os.path.join(data_dir, 'round1', t, '*_ch04.tif')\n",
    "    dapi = imread(dapi_path)\n",
    "    dapi_max = rotate(dapi.max(axis=0), -90)\n",
    "    dapi_max = img_as_ubyte(dapi_max)\n",
    "    imwrite(os.path.join(dapi_rotated_max_path, f'{t}.tif'), dapi_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92fc779-e076-4feb-aed3-fd2f9a1e7e08",
   "metadata": {},
   "source": [
    "## IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b8eb4-1c7a-4c5d-b7b4-3bd2c22fabf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################## SET FILE I/O ##############################\n",
    "\n",
    "### extract the coords information\n",
    "subdir = 'RIBOmap'\n",
    "img_c, img_r = [2048, 2048]\n",
    "\n",
    "data_dir = f'Z:/Data/Processed/2021-11-23-Hu-MouseBrain{subdir}'\n",
    "stitch_dir = 'Z:/jiahao/Github/RIBOmap/segmentation-stitching/'\n",
    "clustermap_dir = os.path.join(data_dir, 'output/clustermap/')\n",
    "\n",
    "orderlist = os.path.join(stitch_dir, subdir, 'orderlist.csv') # list of integers denoting tiles and their positions sequentially\n",
    "inputpath = os.path.join(stitch_dir, subdir, 'round1_merged') # directory containing tile pointers and TileConfiguration outputs\n",
    "dapipath = os.path.join(stitch_dir, subdir, 'dapi') # directory dapi\n",
    "readspath = os.path.join(stitch_dir, 'output', 'segmentation') # segmentation folder containing tile subdirectories and clustermap results within each subdir\n",
    "outputpath = os.path.join(stitch_dir, subdir, 'results')\n",
    "\n",
    "if not os.path.exists(outputpath):\n",
    "    os.mkdir(outputpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92332f7f-2405-4d38-874e-423b6bbcb50e",
   "metadata": {},
   "source": [
    "## Generate coord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed1280-69cd-45bb-b286-1a691aa6e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## READ IN TILE COORDINATES ##############################\n",
    "\n",
    "coords_file = os.path.join(inputpath, 'TileConfiguration.registered.txt')\n",
    "coords_file2 = os.path.join(inputpath, 'TileConfiguration.txt')\n",
    "print(\"Reading in coordinates...\")\n",
    "\n",
    "## precise coords\n",
    "f = open(coords_file)\n",
    "line = f.readline()\n",
    "list = []\n",
    "while line:\n",
    "    if line.startswith('Position'):\n",
    "        a = np.array(line.replace('Position','').replace('.tif; ; (',',').replace(', ',',').replace(')\\n','').split(','))\n",
    "        a = (a.astype(float)+0.5).astype(int).tolist()\n",
    "        list.append(a)\n",
    "    line = f.readline()\n",
    "coords_df = np.array(list)\n",
    "f.close\n",
    "\n",
    "## relative coords\n",
    "f = open(coords_file2)\n",
    "line = f.readline()\n",
    "list = []\n",
    "while line:\n",
    "    if line.startswith('Position'):\n",
    "        a = np.array(line.replace('Position','').replace('.tif; ; (',',').replace(', ',',').replace(')\\n','').split(','))\n",
    "        a = (a.astype(float)+0.5).astype(int).tolist()\n",
    "        a[1:3] = (np.divide(a[1:3],int(img_c*0.9+0.5)) + 0.5).astype(int).tolist()\n",
    "        list.append(a)\n",
    "    line = f.readline()\n",
    "coords_df_v2 = np.array(list)\n",
    "f.close\n",
    "\n",
    "## order list\n",
    "order_df = pd.read_csv(orderlist, header = None)\n",
    "order_df.index = range(1,order_df.shape[0]+1)\n",
    "order_df.columns = ['tile']\n",
    "\n",
    "print(\"Combining read configurations...\")\n",
    "### combine two datasets\n",
    "coords_df2 = pd.DataFrame(coords_df, columns=['index','column','row'], index = coords_df[:,0])\n",
    "coords_df2.drop(columns=coords_df2.columns[0], axis=1, inplace=True)\n",
    "coords_df2_v2 = pd.DataFrame(coords_df_v2, columns=['index','column_count','row_count'], index = coords_df_v2[:,0])\n",
    "coords_df2_v2.drop(columns=coords_df2_v2.columns[0], axis=1, inplace=True)\n",
    "coords_df2['column_count'] = coords_df2_v2.loc[coords_df2.index,'column_count']\n",
    "coords_df2['row_count'] = coords_df2_v2.loc[coords_df2.index,'row_count']\n",
    "\n",
    "## rearrange the index and add tile information\n",
    "coords_df3 = coords_df2.loc[range(1,coords_df2.shape[0] + 1),:]\n",
    "coords_df3['tile'] = order_df['tile']\n",
    "\n",
    "## save\n",
    "coords_df3.to_csv(os.path.join(outputpath,'coords.csv'))\n",
    "\n",
    "print(\"Tuning coordinates...\")\n",
    "## find origin and tuning the coords\n",
    "coords_df3_without_blank = coords_df3.loc[coords_df3['tile'] > 0,:]\n",
    "\n",
    "min_column, min_row = [np.min(coords_df3_without_blank['column']), np.min(coords_df3_without_blank['row'])]\n",
    "max_column, max_row = [np.max(coords_df3_without_blank['column']), np.max(coords_df3_without_blank['row'])]\n",
    "shape_column, shape_row = [max_column - min_column + img_c, max_row - min_row + img_r]\n",
    "\n",
    "coords_df4 = copy.deepcopy(coords_df3)\n",
    "coords_df4['column'] = coords_df4['column'] - min_column\n",
    "coords_df4['row'] = coords_df4['row'] - min_row\n",
    "\n",
    "# save\n",
    "# coords_df4.to_csv(os.path.join(outputpath,'tuned_coords.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528405a4-dd40-4abf-975c-e87010f8ccb1",
   "metadata": {},
   "source": [
    "## Stitch clustermap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd30af-5d62-4374-bded-cc8075a3332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 575\n",
    "tilenum = 394\n",
    "\n",
    "# Get remain_reads.csv for each tile\n",
    "dfpath = os.path.join(clustermap_dir, f\"Position{tilenum:03}\")\n",
    "\n",
    "remain_reads_t = pd.read_csv(os.path.join(clustermap_dir, f\"Position{tilenum:03}\", 'spots.csv'))\n",
    "remain_reads_t['gene'] = remain_reads_t['gene'] - 1\n",
    "remain_reads_t['spot_location_1'] = remain_reads_t['spot_location_1'] - 1\n",
    "remain_reads_t['spot_location_2'] = remain_reads_t['spot_location_2'] - 1\n",
    "remain_reads_t['spot_location_3'] = remain_reads_t['spot_location_3'] - 1\n",
    "\n",
    "# rotate\n",
    "temp1 = remain_reads_t['spot_location_1'].values.copy()\n",
    "temp2 = remain_reads_t['spot_location_2'].values.copy()\n",
    "\n",
    "remain_reads_t['spot_location_1'] = 2048 - temp2\n",
    "remain_reads_t['spot_location_2'] = temp1\n",
    "\n",
    "### read genes.csv\n",
    "genes2seqs, seqs2genes = load_genes(data_dir)\n",
    "\n",
    "### read genelist from clustermap\n",
    "gene_list = pd.read_csv(os.path.join(clustermap_dir, f\"Position{tilenum:03}\", 'genelist.csv'), header=None)\n",
    "gene_list.columns = ['barcode']\n",
    "gene_list['barcode'] = gene_list['barcode'].astype(str)\n",
    "gene_list['gene'] = gene_list['barcode'].map(seqs2genes)\n",
    "\n",
    "### map genes \n",
    "nums2genes = dict(zip(gene_list.index.to_list(), gene_list.gene.to_list()))\n",
    "remain_reads_t['gene'] = remain_reads_t['gene'].map(nums2genes)\n",
    "\n",
    "### remove noise spots\n",
    "remain_reads_t = remain_reads_t.loc[remain_reads_t['clustermap'] != -1, :]\n",
    "\n",
    "# Label with coordinates/tilenum and barcode\n",
    "# remain_reads_t['gridc_gridr_tilenum'] = str(t_grid_c)+\",\"+str(t_grid_r)+\",\"+str(tilenum)\n",
    "\n",
    "## add cell barcode\n",
    "remain_reads_t['cell_barcode'] =  remain_reads_t['clustermap'].values\n",
    "remain_reads_t = remain_reads_t.drop(columns=['clustermap'])\n",
    "\n",
    "# get cell center info\n",
    "label_img = np.zeros([img_c, img_r, 35], dtype=np.uint16)\n",
    "label_img[remain_reads_t['spot_location_2'].values, remain_reads_t['spot_location_1'].values, remain_reads_t['spot_location_3'].values] = remain_reads_t['cell_barcode'].values + 1\n",
    "\n",
    "cell_barcode = []\n",
    "region_centroid = []\n",
    "for i, region in enumerate(tqdm(regionprops(label_img))):\n",
    "    cell_barcode.append(region.label - 1)\n",
    "    region_centroid.append(region.centroid)\n",
    "\n",
    "region_centroid = np.array(region_centroid)\n",
    "cell_center_t = pd.DataFrame({'cell_barcode': cell_barcode, 'column': region_centroid[:, 1], 'row': region_centroid[:, 0], 'z': region_centroid[:, 2]})\n",
    "cell_center_t = cell_center_t.astype(int)\n",
    "print(cell_center_t['cell_barcode'].nunique())\n",
    "\n",
    "## filter cell center based on the dapi mask\n",
    "current_dapi_path = os.path.join(dapipath, f\"Position{order:03}.tif\")\n",
    "current_dapi = tif.imread(current_dapi_path)\n",
    "# current_dapi = median(current_dapi, disk(5))\n",
    "current_dapi = gaussian(current_dapi, sigma=5)\n",
    "current_threshold = threshold_otsu(current_dapi)\n",
    "current_dapi_mask = current_dapi > current_threshold\n",
    "current_dapi_mask = binary_dilation(current_dapi_mask, disk(30))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.imshow(current_dapi_mask)\n",
    "plt.scatter(cell_center_t.loc[:,'column'], cell_center_t.loc[:,'row'], s=3, c='red', alpha = 0.7)\n",
    "plt.show()\n",
    "\n",
    "current_good_cells = current_dapi_mask[cell_center_t.loc[:,'row'], cell_center_t.loc[:,'column']]\n",
    "cell_center_t = cell_center_t.loc[current_good_cells, :]\n",
    "remain_reads_t = remain_reads_t.loc[remain_reads_t['cell_barcode'].isin(cell_center_t['cell_barcode']), :]\n",
    "\n",
    "# remap cell barcode\n",
    "cell_barcode_dict = {}\n",
    "for i, k in enumerate(cell_center_t['cell_barcode'].unique()):\n",
    "    cell_barcode_dict[k] = i\n",
    "cell_center_t['cell_barcode'] = cell_center_t['cell_barcode'].map(cell_barcode_dict)\n",
    "remain_reads_t['cell_barcode'] = remain_reads_t['cell_barcode'].map(cell_barcode_dict)\n",
    "\n",
    "print(cell_center_t['cell_barcode'].nunique())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.imshow(current_dapi_mask)\n",
    "plt.scatter(cell_center_t.loc[:,'column'], cell_center_t.loc[:,'row'], s=3, c='red', alpha = 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6d752-6b61-490b-aaa1-34663827d6bd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################## STITCH TOGETHER TILE COORDINATES ##############################\n",
    "\n",
    "print(\"Adjusting cell center and read coordinates by tile position...\")\n",
    "alignment_thresh = 0.1\n",
    "cell_barcode_min = 0\n",
    "middle_edge = 0\n",
    "\n",
    "# generate empty dataframe\n",
    "remain_reads = pd.DataFrame({'spot_location_1':[],'spot_location_2':[],'spot_location_3':[],'gene':[],'cell_barcode':[],'gridc_gridr_tilenum':[]})\n",
    "cell_center = pd.DataFrame({'cell_barcode':[], 'column':[], 'row':[], 'gridc_gridr_tilenum':[]})\n",
    "\n",
    "# get grid \n",
    "grid_c, grid_r = (np.max(coords_df4.loc[:,['column_count','row_count']]) + 1).tolist()\n",
    "print(grid_c, grid_r)\n",
    "\n",
    "for t_grid_c in trange(0, grid_c):\n",
    "# for t_grid_c in trange(0, 2): # test\n",
    "\n",
    "    median_col_coord = np.median(coords_df4[(coords_df4.column_count == t_grid_c) & (coords_df4.tile != 0)]['column'])\n",
    "    \n",
    "    for t_grid_r in trange(0, grid_r):\n",
    "    # for t_grid_r in trange(23, 25): # test\n",
    "    \n",
    "        median_row_coord = np.median(coords_df4[(coords_df4.row_count == t_grid_r) & (coords_df4.tile != 0)]['row'])\n",
    "        print('\\t[t_grid_c, t_grid_r]: ',str(t_grid_c),' ',str(t_grid_r))\n",
    "        order = t_grid_c * grid_r + t_grid_r + 1\n",
    "\n",
    "        tilenum = coords_df4['tile'][order]\n",
    "\n",
    "        # skip the tile if the tilenum == 0, blank tile\n",
    "        if tilenum == 0:\n",
    "            print(\"\\tBlank tile\")\n",
    "            continue\n",
    "\n",
    "        # get upper left coordinates\n",
    "        upper_left = coords_df4.loc[order, ['column', 'row']]\n",
    "        upper_left_new = copy.deepcopy(upper_left)\n",
    "\n",
    "        # check that tile is appproximately aligned where expected -- otherwise throw out\n",
    "        if upper_left[0] >= (1+alignment_thresh)*median_col_coord and upper_left[0] <= (1-alignment_thresh)*median_col_coord:\n",
    "            if upper_left[1] >= (1+alignment_thresh)*median_row_coord and upper_left[1] <= (1-alignment_thresh)*median_col_coord:\n",
    "                print(\"f\\tTile is aligned too far away from its expected position.\")\n",
    "                print(\"f\\tTile coord: [{upper_left[0]}, {upper_left[1]}]. Median coord: [{median_col_coord}, {median_row_coord}]\")\n",
    "                continue\n",
    "\n",
    "        # judgment\n",
    "        t_grid_c_previous = t_grid_c - 1\n",
    "        t_grid_r_previous = t_grid_r - 1\n",
    "\n",
    "        # condition1: if left one is not blank, then calculate middle overlap\n",
    "        if t_grid_c_previous >= 0: # if a left tile exists\n",
    "            order_t = t_grid_c_previous * grid_r + t_grid_r + 1 # order of left tile\n",
    "            if coords_df4.loc[order_t,'tile'] != 0: # if it's not blank, calculate new middle edge. Otherwise, use old middle edge\n",
    "                middle_edge = np.int((coords_df4.loc[order_t,'column'] + img_c - upper_left[0])/2 + 0.5) # calculate middle overlap\n",
    "\n",
    "                if middle_edge >= 0: \n",
    "                    upper_left_new[0] = middle_edge + upper_left[0]\n",
    "\n",
    "        # condition2: if upper one is empty or blank\n",
    "        if t_grid_r_previous >= 0:\n",
    "            order_t = t_grid_c * grid_r + t_grid_r_previous + 1\n",
    "            if coords_df4.loc[order_t,'tile'] != 0:\n",
    "                middle_edge = np.int((coords_df4.loc[order_t,'row'] + img_c - upper_left[1])/2 + 0.5)\n",
    "\n",
    "                if middle_edge >= 0: \n",
    "                    upper_left_new[1] = middle_edge + upper_left[1]\n",
    "\n",
    "        ### stitch\n",
    "        # Get remain_reads.csv for each tile\n",
    "        dfpath = os.path.join(clustermap_dir, f\"Position{tilenum:03}\")\n",
    "        if not os.path.exists(os.path.join(dfpath, 'spots.csv')):\n",
    "            print('\\tNo reads file for this tile')\n",
    "            continue\n",
    "\n",
    "        remain_reads_t = pd.read_csv(os.path.join(clustermap_dir, f\"Position{tilenum:03}\", 'spots.csv'))\n",
    "        remain_reads_t['gene'] = remain_reads_t['gene'] - 1\n",
    "        remain_reads_t['spot_location_1'] = remain_reads_t['spot_location_1'] - 1\n",
    "        remain_reads_t['spot_location_2'] = remain_reads_t['spot_location_2'] - 1\n",
    "        remain_reads_t['spot_location_3'] = remain_reads_t['spot_location_3'] - 1\n",
    "\n",
    "        # rotate\n",
    "        temp1 = remain_reads_t['spot_location_1'].values.copy()\n",
    "        temp2 = remain_reads_t['spot_location_2'].values.copy()\n",
    "\n",
    "        remain_reads_t['spot_location_1'] = 2048 - temp2\n",
    "        remain_reads_t['spot_location_2'] = temp1\n",
    "\n",
    "        ### read genes.csv\n",
    "        genes2seqs, seqs2genes = load_genes(data_dir)\n",
    "\n",
    "        ### read genelist from clustermap\n",
    "        gene_list = pd.read_csv(os.path.join(clustermap_dir, f\"Position{tilenum:03}\", 'genelist.csv'), header=None)\n",
    "        gene_list.columns = ['barcode']\n",
    "        gene_list['barcode'] = gene_list['barcode'].astype(str)\n",
    "        gene_list['gene'] = gene_list['barcode'].map(seqs2genes)\n",
    "\n",
    "        ### map genes \n",
    "        nums2genes = dict(zip(gene_list.index.to_list(), gene_list.gene.to_list()))\n",
    "        remain_reads_t['gene'] = remain_reads_t['gene'].map(nums2genes)\n",
    "\n",
    "        ### remove noise spots\n",
    "        remain_reads_t = remain_reads_t.loc[remain_reads_t['clustermap'] != -1, :]\n",
    "\n",
    "        # skip current tile if no reads left\n",
    "        if remain_reads_t.shape[0] == 0:\n",
    "            print(\"\\tNo reads found in remain_reads.csv for this tile\")\n",
    "            continue\n",
    "\n",
    "        # Label with coordinates/tilenum and barcode\n",
    "        remain_reads_t['gridc_gridr_tilenum'] = str(t_grid_c)+\",\"+str(t_grid_r)+\",\"+str(tilenum)\n",
    "\n",
    "        # remap cell barcode\n",
    "        remain_reads_t['cell_barcode'] =  remain_reads_t['clustermap'].values\n",
    "        remain_reads_t = remain_reads_t.drop(columns=['clustermap'])\n",
    "\n",
    "        # get cell center info\n",
    "        label_img = np.zeros([img_c, img_r, 35], dtype=np.uint16)\n",
    "        label_img[remain_reads_t['spot_location_2'].values, remain_reads_t['spot_location_1'].values, remain_reads_t['spot_location_3'].values] = remain_reads_t['cell_barcode'].values + 1\n",
    "\n",
    "        cell_barcode = []\n",
    "        region_centroid = []\n",
    "        for i, region in enumerate(tqdm(regionprops(label_img))):\n",
    "            cell_barcode.append(region.label - 1)\n",
    "            region_centroid.append(region.centroid)\n",
    "\n",
    "        region_centroid = np.array(region_centroid)\n",
    "        cell_center_t = pd.DataFrame({'cell_barcode': cell_barcode, 'column': region_centroid[:, 1], 'row': region_centroid[:, 0], 'z': region_centroid[:, 2]})\n",
    "        cell_center_t = cell_center_t.astype(int)\n",
    "\n",
    "        ## filter cell center based on the dapi mask\n",
    "        current_dapi_path = os.path.join(dapipath, f\"Position{order:03}.tif\")\n",
    "        current_dapi = tif.imread(current_dapi_path)\n",
    "        # current_dapi = median(current_dapi, disk(5))\n",
    "        current_dapi = gaussian(current_dapi, sigma=5)\n",
    "        current_threshold = threshold_otsu(current_dapi)\n",
    "        current_dapi_mask = current_dapi > current_threshold\n",
    "        current_dapi_mask = binary_dilation(current_dapi_mask, disk(30))\n",
    "\n",
    "        current_good_cells = current_dapi_mask[cell_center_t.loc[:,'row'], cell_center_t.loc[:,'column']]\n",
    "        cell_center_t = cell_center_t.loc[current_good_cells, :]\n",
    "        remain_reads_t = remain_reads_t.loc[remain_reads_t['cell_barcode'].isin(cell_center_t['cell_barcode']), :]\n",
    "\n",
    "        # remap cell barcode\n",
    "        cell_barcode_dict = {}\n",
    "        for i, k in enumerate(cell_center_t['cell_barcode'].unique()):\n",
    "            cell_barcode_dict[k] = i\n",
    "        cell_center_t['cell_barcode'] = cell_center_t['cell_barcode'].map(cell_barcode_dict)\n",
    "        remain_reads_t['cell_barcode'] = remain_reads_t['cell_barcode'].map(cell_barcode_dict)\n",
    "\n",
    "        # change cell barcode\n",
    "        remain_reads_t['cell_barcode'] = remain_reads_t['cell_barcode'] + cell_barcode_min\n",
    "        cell_center_t['cell_barcode'] = cell_center_t['cell_barcode'] + cell_barcode_min\n",
    "\n",
    "        # modify cell center\n",
    "        cell_center_t['gridc_gridr_tilenum'] = str(t_grid_c)+\",\"+str(t_grid_r)+\",\"+str(tilenum)\n",
    "\n",
    "        ### stitch\n",
    "        # Adjust spot_location_1 (column)\n",
    "        remain_reads_t['spot_location_1'] = remain_reads_t['spot_location_1'] + upper_left[0]\n",
    "        cell_center_t['column'] = cell_center_t['column']  + upper_left[0]\n",
    "\n",
    "        # Adjust spot_location_2 (row)\n",
    "        remain_reads_t['spot_location_2'] = remain_reads_t['spot_location_2'] + upper_left[1]\n",
    "        cell_center_t['row'] = cell_center_t['row']  + upper_left[1]\n",
    "\n",
    "        # print(f\"\\ttile: Position{tilenum:03}\")\n",
    "        # print(f\"\\tInitial remain_reads: {len(remain_reads_t)}\")\n",
    "        # print(f\"\\tInitial cell centers: {len(cell_center_t)}\")\n",
    "\n",
    "        ## keep the cells within upper_left_new for `remain_reads`, `cell_center`\n",
    "        cell_center = cell_center.loc[(cell_center['column'] <= upper_left_new[0])|(cell_center['row'] <= upper_left_new[1]) | (cell_center['row'] >= upper_left_new[1]+img_r),:] \n",
    "        remain_reads = remain_reads.loc[remain_reads['cell_barcode'].isin(cell_center['cell_barcode']),:]\n",
    "\n",
    "        ## keep the cells beyond upper_left_new for `remain_reads_t`, `cell_center_t`\n",
    "        cell_center_t = cell_center_t.loc[(cell_center_t['column'] > upper_left_new[0])&(cell_center_t['row'] > upper_left_new[1]),:]\n",
    "        remain_reads_t = remain_reads_t.loc[remain_reads_t['cell_barcode'].isin(cell_center_t['cell_barcode']),:]\n",
    "        # print(f\"\\tReads beyond upper_left_new: {len(remain_reads_t)}\")\n",
    "        # print(f\"\\tCell centers beyond upper_left_new: {len(cell_center_t)}\")\n",
    "\n",
    "        ## append\n",
    "        cell_center = pd.concat((cell_center, cell_center_t), axis=0)\n",
    "        print(f\"\\tNew total number of cell centers: {len(cell_center)}\")\n",
    "        remain_reads = pd.concat((remain_reads, remain_reads_t), axis=0)\n",
    "        print(f\"\\tNew total number of reads: {len(remain_reads)}\")\n",
    "\n",
    "        # Update minimum cell barcode\n",
    "        if cell_center_t.shape[0] > 0:\n",
    "            cell_barcode_min = np.max(cell_center_t['cell_barcode']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79098628-4a0d-4521-b7cb-84bfa6c19f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_reads.to_csv(f'Z:/Data/Analyzed/2021-11-23-Hu-MouseBrain/{subdir}/remain_reads.csv')\n",
    "cell_center.to_csv(f'Z:/Data/Analyzed/2021-11-23-Hu-MouseBrain/{subdir}/cell_center.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1272fe-0998-4fe5-9c8e-6aeb0f376efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### polish after stitch\n",
    "print(\"Polishing stitch...\")\n",
    "\n",
    "# filter the repeated reads\n",
    "remain_reads = remain_reads.drop(columns=['is_noise'])\n",
    "remain_reads = remain_reads.drop_duplicates(subset = None, keep = 'first')\n",
    "\n",
    "# reset index\n",
    "cell_center.reset_index(inplace = True, drop = True)\n",
    "remain_reads.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# transfer float to integer\n",
    "remain_reads['spot_location_1'] = remain_reads['spot_location_1'].astype(int)\n",
    "remain_reads['spot_location_2'] = remain_reads['spot_location_2'].astype(int)\n",
    "remain_reads['spot_location_3'] = remain_reads['spot_location_3'].astype(int)\n",
    "remain_reads['cell_barcode'] = remain_reads['cell_barcode'].astype(int)\n",
    "\n",
    "cell_center['column'] = cell_center['column'].astype(int)\n",
    "cell_center['row'] = cell_center['row'].astype(int)\n",
    "cell_center['z'] = cell_center['z'].astype(int)\n",
    "cell_center['cell_barcode'] = cell_center['cell_barcode'].astype(int)\n",
    "\n",
    "### deal with multi-assigned reads\n",
    "print(\"Removing reads assigned to multiple cell centers:\")\n",
    "# find duplicated reads\n",
    "remain_reads_check = remain_reads.loc[:, ['spot_location_1', 'spot_location_2', 'spot_location_3']]\n",
    "remain_reads_check.columns = ['col','row','z']\n",
    "remain_reads_check['coors'] = remain_reads_check['col'].apply(str).str.cat(remain_reads_check['row'].apply(str),sep='-').str.cat(remain_reads_check['z'].apply(str),sep='-')\n",
    "remain_reads_check_counts = remain_reads_check['coors'].value_counts()\n",
    "repeat_reads = remain_reads_check_counts[remain_reads_check_counts>1]\n",
    "\n",
    "# assign the duplicated reads to the closest cell\n",
    "filter_index = []\n",
    "for i in trange(len(repeat_reads)):\n",
    "\n",
    "    repeat_reads_index = remain_reads_check.index[remain_reads_check['coors'] == repeat_reads.index[i]]\n",
    "    vec1 = remain_reads.loc[repeat_reads_index[0], ['spot_location_1', 'spot_location_2', 'spot_location_3']].tolist()\n",
    "    repeat_reads_cell_index = cell_center['cell_barcode'].isin(remain_reads.loc[repeat_reads_index, 'cell_barcode'])\n",
    "    repeat_reads_cell = cell_center.loc[repeat_reads_cell_index, :]\n",
    "    closest_index = closest_node(vec1,np.array(repeat_reads_cell.loc[:, ['column','row','z']]).tolist())[1]\n",
    "    selected_cell = repeat_reads_cell.iloc[closest_index, 0]\n",
    "    filter_index.extend(repeat_reads_index[np.logical_not(remain_reads.loc[repeat_reads_index, 'cell_barcode'] == selected_cell)].tolist())\n",
    "\n",
    "print(\"read counts before filtering multi-assigned reads: \" + str(remain_reads.shape[0]))\n",
    "remain_reads.drop(index = filter_index, inplace = True)\n",
    "remain_reads.reset_index(inplace = True, drop = True)\n",
    "print(\"read counts after filtering multi-assigned reads: \" + str(remain_reads.shape[0]))\n",
    "\n",
    "# print(\"Saving cell_center.csv and remain_reads.csv\")\n",
    "# cell_center.to_csv(os.path.join(outputpath, 'cell_center.csv'))\n",
    "# remain_reads.to_csv(os.path.join(outputpath, 'remain_reads.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912c554-dee5-4e89-b5ba-0626ae871b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_reads.to_csv(f'Z:/Data/Analyzed/2021-11-23-Hu-MouseBrain/{subdir}/remain_reads_polished.csv')\n",
    "cell_center.to_csv(f'Z:/Data/Analyzed/2021-11-23-Hu-MouseBrain/{subdir}/cell_center_polished.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103d659-710e-4b0f-9723-29197c80416a",
   "metadata": {},
   "source": [
    "## Stitch clustermap with background reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab561ca-4ed4-43bf-8436-c0a5db438179",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################## STITCH TOGETHER TILE COORDINATES ##############################\n",
    "\n",
    "print(\"Adjusting cell center and read coordinates by tile position...\")\n",
    "alignment_thresh = 0.1\n",
    "cell_barcode_min = 0\n",
    "middle_edge = 0\n",
    "\n",
    "# generate empty dataframe\n",
    "remain_reads = pd.DataFrame({'spot_location_1':[],'spot_location_2':[],'spot_location_3':[],'gene':[],'cell_barcode':[],'gridc_gridr_tilenum':[]})\n",
    "cell_center = pd.DataFrame({'cell_barcode':[], 'column':[], 'row':[], 'gridc_gridr_tilenum':[]})\n",
    "\n",
    "# get grid \n",
    "grid_c, grid_r = (np.max(coords_df4.loc[:,['column_count','row_count']]) + 1).tolist()\n",
    "print(grid_c, grid_r)\n",
    "\n",
    "for t_grid_c in trange(0, grid_c):\n",
    "# for t_grid_c in trange(0, 2): # test\n",
    "\n",
    "    median_col_coord = np.median(coords_df4[(coords_df4.column_count == t_grid_c) & (coords_df4.tile != 0)]['column'])\n",
    "    \n",
    "    for t_grid_r in trange(0, grid_r):\n",
    "    # for t_grid_r in trange(23, 25): # test\n",
    "    \n",
    "        median_row_coord = np.median(coords_df4[(coords_df4.row_count == t_grid_r) & (coords_df4.tile != 0)]['row'])\n",
    "        print('\\t[t_grid_c, t_grid_r]: ',str(t_grid_c),' ',str(t_grid_r))\n",
    "        order = t_grid_c * grid_r + t_grid_r + 1\n",
    "\n",
    "        tilenum = coords_df4['tile'][order]\n",
    "\n",
    "        # skip the tile if the tilenum == 0, blank tile\n",
    "        if tilenum == 0:\n",
    "            print(\"\\tBlank tile\")\n",
    "            continue\n",
    "\n",
    "        # get upper left coordinates\n",
    "        upper_left = coords_df4.loc[order, ['column', 'row']]\n",
    "        upper_left_new = copy.deepcopy(upper_left)\n",
    "\n",
    "        # check that tile is appproximately aligned where expected -- otherwise throw out\n",
    "        if upper_left[0] >= (1+alignment_thresh)*median_col_coord and upper_left[0] <= (1-alignment_thresh)*median_col_coord:\n",
    "            if upper_left[1] >= (1+alignment_thresh)*median_row_coord and upper_left[1] <= (1-alignment_thresh)*median_col_coord:\n",
    "                print(\"f\\tTile is aligned too far away from its expected position.\")\n",
    "                print(\"f\\tTile coord: [{upper_left[0]}, {upper_left[1]}]. Median coord: [{median_col_coord}, {median_row_coord}]\")\n",
    "                continue\n",
    "\n",
    "        # judgment\n",
    "        t_grid_c_previous = t_grid_c - 1\n",
    "        t_grid_r_previous = t_grid_r - 1\n",
    "\n",
    "        # condition1: if left one is not blank, then calculate middle overlap\n",
    "        if t_grid_c_previous >= 0: # if a left tile exists\n",
    "            order_t = t_grid_c_previous * grid_r + t_grid_r + 1 # order of left tile\n",
    "            if coords_df4.loc[order_t,'tile'] != 0: # if it's not blank, calculate new middle edge. Otherwise, use old middle edge\n",
    "                middle_edge = np.int((coords_df4.loc[order_t,'column'] + img_c - upper_left[0])/2 + 0.5) # calculate middle overlap\n",
    "\n",
    "                if middle_edge >= 0: \n",
    "                    upper_left_new[0] = middle_edge + upper_left[0]\n",
    "\n",
    "        # condition2: if upper one is empty or blank\n",
    "        if t_grid_r_previous >= 0:\n",
    "            order_t = t_grid_c * grid_r + t_grid_r_previous + 1\n",
    "            if coords_df4.loc[order_t,'tile'] != 0:\n",
    "                middle_edge = np.int((coords_df4.loc[order_t,'row'] + img_c - upper_left[1])/2 + 0.5)\n",
    "\n",
    "                if middle_edge >= 0: \n",
    "                    upper_left_new[1] = middle_edge + upper_left[1]\n",
    "\n",
    "        ### stitch\n",
    "        # Get remain_reads.csv for each tile\n",
    "        dfpath = os.path.join(clustermap_dir, f\"Position{tilenum:03}\")\n",
    "        if not os.path.exists(os.path.join(dfpath, 'spots.csv')):\n",
    "            print('\\tNo reads file for this tile')\n",
    "            continue\n",
    "\n",
    "        remain_reads_t = pd.read_csv(os.path.join(clustermap_dir, f\"Position{tilenum:03}\", 'spots.csv'))\n",
    "        remain_reads_t['gene'] = remain_reads_t['gene'] - 1\n",
    "        remain_reads_t['spot_location_1'] = remain_reads_t['spot_location_1'] - 1\n",
    "        remain_reads_t['spot_location_2'] = remain_reads_t['spot_location_2'] - 1\n",
    "        remain_reads_t['spot_location_3'] = remain_reads_t['spot_location_3'] - 1\n",
    "\n",
    "        # rotate\n",
    "        temp1 = remain_reads_t['spot_location_1'].values.copy()\n",
    "        temp2 = remain_reads_t['spot_location_2'].values.copy()\n",
    "\n",
    "        remain_reads_t['spot_location_1'] = 2048 - temp2\n",
    "        remain_reads_t['spot_location_2'] = temp1\n",
    "\n",
    "        ### read genes.csv\n",
    "        genes2seqs, seqs2genes = load_genes(data_dir)\n",
    "\n",
    "        ### read genelist from clustermap\n",
    "        gene_list = pd.read_csv(os.path.join(clustermap_dir, f\"Position{tilenum:03}\", 'genelist.csv'), header=None)\n",
    "        gene_list.columns = ['barcode']\n",
    "        gene_list['barcode'] = gene_list['barcode'].astype(str)\n",
    "        gene_list['gene'] = gene_list['barcode'].map(seqs2genes)\n",
    "\n",
    "        ### map genes \n",
    "        nums2genes = dict(zip(gene_list.index.to_list(), gene_list.gene.to_list()))\n",
    "        remain_reads_t['gene'] = remain_reads_t['gene'].map(nums2genes)\n",
    "\n",
    "        ### get background spots\n",
    "        remain_reads_t = remain_reads_t.loc[remain_reads_t['clustermap'] == -1, :]\n",
    "\n",
    "        # skip current tile if no reads left\n",
    "        if remain_reads_t.shape[0] == 0:\n",
    "            print(\"\\tNo reads found in remain_reads.csv for this tile\")\n",
    "            continue\n",
    "\n",
    "        # Label with coordinates/tilenum and barcode\n",
    "        remain_reads_t['gridc_gridr_tilenum'] = str(t_grid_c)+\",\"+str(t_grid_r)+\",\"+str(tilenum)\n",
    "\n",
    "        ### stitch\n",
    "        # Adjust spot_location_1 (column)\n",
    "        remain_reads_t['spot_location_1'] = remain_reads_t['spot_location_1'] + upper_left[0]\n",
    "\n",
    "        # Adjust spot_location_2 (row)\n",
    "        remain_reads_t['spot_location_2'] = remain_reads_t['spot_location_2'] + upper_left[1]\n",
    "\n",
    "        ## append\n",
    "        remain_reads = pd.concat((remain_reads, remain_reads_t), axis=0)\n",
    "        print(f\"\\tNew total number of reads: {len(remain_reads)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aaf9cf-9957-4380-ba1a-4010e5c06e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_reads.to_csv(f'Z:/Data/Analyzed/2021-11-23-Hu-MouseBrain/{subdir}/background_reads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f31d7-9f8d-45bd-b0fa-6fad91b4a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "### polish after stitch\n",
    "\n",
    "# filter the repeated reads\n",
    "remain_reads['cell_barcode'] = -1\n",
    "remain_reads = remain_reads.drop(columns=['is_noise', 'clustermap'])\n",
    "remain_reads = remain_reads.drop_duplicates(subset=['spot_location_1', 'spot_location_2', 'spot_location_3'], keep='first')\n",
    "\n",
    "# reset index\n",
    "remain_reads.reset_index(inplace = True, drop = True)\n",
    "\n",
    "remain_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18eb56b-f572-4f23-be94-46395b6c1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_reads.to_csv(f'Z:/Data/Analyzed/2021-11-23-Hu-MouseBrain/{subdir}/background_reads_polished.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884bb145-39b5-47db-8ddd-ed03732eb5d7",
   "metadata": {},
   "source": [
    "## H5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92934fe1-8fce-4b0b-ae21-11061a90bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in gene list\n",
    "# gene_path = os.path.join('Z:/Data/Processed/2021-11-23-Hu-MouseBrainSTARmap/genes.csv')\n",
    "# gene_names = pd.read_csv(gene_path, header=None, names=[\"Gene Name\", \"Barcode\"])[\"Gene Name\"]\n",
    "\n",
    "# # Get I/O paths\n",
    "# sample = 'starmap'\n",
    "# data_dir = 'Z:/jiahao/Github/RIBOmap/segmentation-stitching/'\n",
    "# inputpath = os.path.join(data_dir, sample)\n",
    "# # outputpaths.append(os.path.join(inputpath, 'analysis'))\n",
    "\n",
    "# # Read in reads assignment results\n",
    "# # cell_center = pd.read_csv(os.path.join(inputpath, 'results/cell_center.csv'),index_col=0)\n",
    "# # remain_reads = pd.read_csv(os.path.join(inputpath,'results/remain_reads.csv'), index_col=0, na_filter=False)\n",
    "# # cell_center_index = copy.deepcopy(cell_center)\n",
    "# # cell_center_index.set_index('cell_barcode', inplace = True,drop = True) \n",
    "# remain_reads_t = remain_reads.loc[:,['cell_barcode','gene']]\n",
    "# remain_reads_t['value'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c78e2-5d4c-432c-a673-473091fe4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## Create cell-by-gene expression matrix\n",
    "# exp_matrix = pd.pivot_table(remain_reads_t, index='cell_barcode', columns='gene', aggfunc='count', fill_value = 0)\n",
    "# var_raw = [str(s2) for (s1,s2) in exp_matrix.columns.tolist()]\n",
    "# exp_matrix.set_axis(var_raw, axis = 1, inplace=True)\n",
    "# #obs = cell_center_index.loc[exp_matrix.index.values,['column','row','z_axis']]\n",
    "# #obs.reset_index(inplace = True,drop = True) ### obs as cell location\n",
    "# obs = pd.DataFrame(index=exp_matrix.index)  \n",
    "# var = pd.DataFrame(index=var_raw)  ## index as gene name\n",
    "# if len(var) == len(gene_names):\n",
    "#     print(f\"All genes in gene list found in {sample}\")\n",
    "# else:\n",
    "#     print(f\"Not all genes in gene list found in {sample}\")\n",
    "\n",
    "# # Store in anndata object\n",
    "# adata = ad.AnnData(X=np.array(exp_matrix),\n",
    "#                 var=var,\n",
    "#                 obs=obs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1f7a1-6349-4269-bbd4-dafbd82a10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in reads assignment results\n",
    "gene_path = os.path.join('Z:/Data/Analyzed/2021-11-23-Hu-MouseBrain/genes.csv')\n",
    "gene_names = pd.read_csv(gene_path, header=None, names=[\"Gene Name\", \"Barcode\"])[\"Gene Name\"]\n",
    "\n",
    "# cell_center = pd.read_csv(os.path.join(inputpath, 'results/cell_center.csv'),index_col=0)\n",
    "# remain_reads = pd.read_csv(os.path.join(inputpath,'results/remain_reads.csv'),index_col=0, na_filter=False)\n",
    "cell_center_index = copy.deepcopy(cell_center)\n",
    "cell_center_index.set_index('cell_barcode', inplace = True, drop = True) \n",
    "remain_reads_t = remain_reads.loc[:,['cell_barcode','gene']]\n",
    "remain_reads_t['value'] = 1\n",
    "\n",
    "# ## Create cell-by-gene expression matrix\n",
    "exp_matrix = pd.pivot_table(remain_reads_t, index='cell_barcode', columns='gene', aggfunc='count', fill_value = 0)\n",
    "var_raw = [str(s2) for (s1,s2) in exp_matrix.columns.tolist()]\n",
    "exp_matrix.set_axis(var_raw,axis = 1,inplace=True)\n",
    "obs = cell_center_index.loc[exp_matrix.index.values,['column','row','z']]\n",
    "obs.reset_index(inplace = True,drop = True) ### obs as cell location\n",
    "var = pd.DataFrame(index=var_raw)  ## index as gene name\n",
    "\n",
    "# Store in anndata object\n",
    "adata = ad.AnnData(X=np.array(exp_matrix),\n",
    "                var=var,\n",
    "                obs=obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00042146-7408-4f07-9508-68a113015c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab1110-9b78-434f-9bef-90573b7ad404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "adata.write_h5ad(f'Z:/Data/Analyzed/2021-11-23-Hu-MouseBrain/{subdir}/{date}-{subdir}-raw.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551f35b-751f-4f4b-9f17-5a3ed3f8f2b9",
   "metadata": {},
   "source": [
    "## Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e841994-7f93-4de0-94b8-44a26a78f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spots\n",
    "cell_ids = remain_reads['cell_barcode']\n",
    "cells_unique = np.unique(cell_ids)\n",
    "spots_repr = np.array(remain_reads[['spot_location_2', 'spot_location_1']])[cell_ids>=0]\n",
    "cell_ids = cell_ids[cell_ids>=0]                \n",
    "cmap = np.random.rand(int(max(cell_ids)+1), 3)\n",
    "fig, ax = plt.subplots(figsize=(40,40))\n",
    "ax.scatter(spots_repr[:,1], spots_repr[:,0], c=cmap[[int(x) for x in cell_ids]], s=1, alpha=.5)\n",
    "ax.scatter(cell_center.loc[:,'column'], cell_center.loc[:,'row'], c='r', s=3)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc979cc-4d6a-4a2d-8f22-bdbc4694e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[40,40])\n",
    "plt.scatter(remain_reads.loc[:,'spot_location_1'], remain_reads.loc[:,'spot_location_2'], s=1, alpha=0.2)\n",
    "plt.scatter(cell_center.loc[:,'column'], cell_center.loc[:,'row'], s=3, c='red', alpha = 0.7)\n",
    "\n",
    "# plt.scatter(remain_reads.loc[:,'spot_location_1'], shape_row - remain_reads.loc[:,'spot_location_2'], s=1, alpha=0.2)\n",
    "# plt.scatter(cell_center.loc[:,'column'], shape_row - cell_center.loc[:,'row'], s=3, c='red', alpha = 0.7)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea29b2-0056-49bf-b95c-ce2a5df4eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[40,40])\n",
    "plt.scatter(remain_reads.loc[:,'spot_location_1'], remain_reads.loc[:,'spot_location_2'], s=1, alpha=0.2)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad753621-b382-4f52-b12f-d37e380c3934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d3a21-0136-4de8-ae94-0268d55cf966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
